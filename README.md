# ğŸ“Š Sistema IoT Big Data ETL con Machine Learning

Sistema completo de procesamiento en tiempo real de datos IoT con capacidades de Big Data y predicciones mediante Machine Learning usando Apache Spark.

## ğŸ¯ DescripciÃ³n del Proyecto

Pipeline ETL distribuido que procesa datos de sensores IoT en tiempo real, almacena informaciÃ³n en bases de datos relacionales y NoSQL, y genera predicciones futuras mediante modelos de Machine Learning.

### Sensores Soportados:
- **EM310 Soterrados** - Sensores de distancia
- **EM500 CO2** - Sensores de calidad de aire (CO2, temperatura, humedad, presiÃ³n)
- **WS302 Sonido** - Sensores de nivel de ruido (LAeq, LAI, LAImax)

## ğŸ—ï¸ Arquitectura del Sistema

```
Productores IoT â†’ Kafka â†’ Spark Streaming â†’ MySQL + MongoDB
                                    â†“
                            Spark ML (RegresiÃ³n)
                                    â†“
                          Predicciones (24h futuro)
                                    â†“
                          Dashboard Streamlit
```

### Componentes Principales:

1. **Apache Kafka** - Message broker para streaming de datos
2. **Apache Spark** - Procesamiento distribuido y Machine Learning
3. **MySQL** - Base de datos relacional para datos estructurados
4. **MongoDB Atlas** - Base de datos NoSQL para datos no estructurados
5. **Streamlit** - Dashboard interactivo con visualizaciones
6. **Docker** - ContenerizaciÃ³n de todos los servicios

## ğŸš€ Inicio RÃ¡pido

### OpciÃ³n 1: Script AutomÃ¡tico (Recomendado)

```cmd
.\setup.cmd
```

Este script automÃ¡ticamente:
- âœ… Verifica e instala Docker Desktop
- âœ… Detiene contenedores existentes
- âœ… Construye las imÃ¡genes Docker
- âœ… Inicia todos los servicios
- âœ… Verifica el estado de los servicios

### OpciÃ³n 2: Manual

```bash
# 1. Construir imÃ¡genes
docker-compose build

# 2. Iniciar servicios principales
docker-compose up -d zookeeper kafka mysql mongodb spark-master spark-worker

# 3. Esperar 30 segundos para inicializaciÃ³n

# 4. Iniciar productores
cd app/producers
python producer_em310.py &
python producer_em500.py &
python producer_ws302.py &

# 5. Iniciar consumers y dashboard
docker-compose up -d spark-consumer-em310 spark-consumer-em500 spark-consumer-ws302 dashboard

# 6. Ejecutar job de ML (opcional)
docker exec spark-ml-job /opt/spark/bin/spark-submit --master local[2] /opt/spark/app/etl/spark_ml_forecast.py
```

## ğŸ“‹ Requisitos Previos

- **Docker Desktop** (Windows/Mac) o **Docker + Docker Compose** (Linux)
- **Python 3.9+** (para productores locales)
- **8GB RAM mÃ­nimo** (16GB recomendado)
- **10GB espacio en disco**

### Puertos Utilizados:

| Servicio | Puerto | DescripciÃ³n |
|----------|--------|-------------|
| Dashboard | 8501 | Interfaz web Streamlit |
| Kafka | 9092 | Broker interno |
| Kafka | 29092 | Broker externo |
| MySQL | 3307 | Base de datos |
| MongoDB | 27017 | Base de datos NoSQL |
| Spark Master UI | 18080 | Interfaz web Spark |
| Spark Worker UI | 8081 | Worker UI |
| Zookeeper | 2181 | CoordinaciÃ³n Kafka |

## ğŸ¤– Machine Learning

### Modelos Implementados:

El sistema entrena **3 modelos de regresiÃ³n** por cada mÃ©trica:

1. **Linear Regression** - Modelo lineal simple y rÃ¡pido
2. **Random Forest Regressor** - Ensemble de Ã¡rboles de decisiÃ³n
3. **Gradient Boosting Trees (GBT)** - Boosting secuencial

**SelecciÃ³n AutomÃ¡tica**: El sistema evalÃºa los 3 modelos usando RÂ² y selecciona automÃ¡ticamente el mejor para cada mÃ©trica.

### MÃ©tricas Predichas:

- **EM310**: distance (1 mÃ©trica) â†’ 24 predicciones
- **EM500**: co2, temperature, humidity, pressure (4 mÃ©tricas) â†’ 96 predicciones
- **WS302**: LAeq, LAI, LAImax (3 mÃ©tricas) â†’ 72 predicciones

**Total: 192 predicciones** para las prÃ³ximas 24 horas

### CaracterÃ­sticas de ML:

- âœ… DetecciÃ³n de anomalÃ­as con Z-score (Â±3Ïƒ)
- âœ… EvaluaciÃ³n con RÂ² (coeficiente de determinaciÃ³n)
- âœ… Feature engineering automÃ¡tico
- âœ… Train/Test split (80/20)
- âœ… Predicciones horarias para 24 horas

### Ejecutar Job de ML:

```bash
# Actualizar predicciones con datos mÃ¡s recientes
docker exec spark-ml-job /opt/spark/bin/spark-submit --master local[2] /opt/spark/app/etl/spark_ml_forecast.py
```

**Nota**: Las predicciones NO se actualizan automÃ¡ticamente. Ejecuta este comando cuando quieras regenerar predicciones con los datos mÃ¡s recientes.

## ğŸ“Š Dashboard

Accede al dashboard en: **http://localhost:8501**

### CaracterÃ­sticas:

- ğŸ“ˆ Visualizaciones interactivas con Plotly
- ğŸ”„ Auto-refresh cada 10 segundos
- ğŸ“Š GrÃ¡ficos separados para:
  - Datos histÃ³ricos en tiempo real
  - Predicciones ML futuras
- ğŸ“‰ EstadÃ­sticas por sensor (promedio, mÃ¡ximo, mÃ­nimo)
- ğŸ¯ Selector de tipo de sensor
- ğŸ“ Control de cantidad de registros a mostrar

## ğŸ’¾ Bases de Datos

### MySQL (Datos Estructurados)

**Tablas:**
- `em310_soterrados` - Datos de sensores de distancia
- `em500_co2` - Datos de calidad de aire
- `ws302_sonido` - Datos de nivel de ruido
- `predicciones` - Predicciones ML con modelo usado

**ConexiÃ³n:**
```
Host: localhost
Port: 3307
User: root
Password: Os51t=Ag/3=B
Database: emergentETL
```

### MongoDB Atlas (Datos No Estructurados)

**Colecciones:**
- `em310_soterrados`
- `em500_co2`
- `ws302_sonido`

**URI:** `mongodb+srv://BDETLEmergentes:12345@bdemergetesetl.lwsmez4.mongodb.net/`

## ğŸ“ Estructura del Proyecto

```
EmergentesETL/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”œâ”€â”€ app.py                    # Dashboard Streamlit
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ spark_consumer_em310.py   # Consumer EM310
â”‚   â”‚   â”œâ”€â”€ spark_consumer_em500.py   # Consumer EM500
â”‚   â”‚   â”œâ”€â”€ spark_consumer_ws302.py   # Consumer WS302
â”‚   â”‚   â””â”€â”€ spark_ml_forecast.py      # Job de Machine Learning
â”‚   â””â”€â”€ producers/
â”‚       â”œâ”€â”€ producer_em310.py         # Productor EM310
â”‚       â”œâ”€â”€ producer_em500.py         # Productor EM500
â”‚       â””â”€â”€ producer_ws302.py         # Productor WS302
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ init.sql                      # Schema MySQL
â”œâ”€â”€ docker-compose.yml                # OrquestaciÃ³n de servicios
â”œâ”€â”€ Dockerfile                        # Imagen Spark custom
â”œâ”€â”€ setup.cmd                         # Script de instalaciÃ³n automÃ¡tica
â””â”€â”€ README.md
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

**MySQL:**
```env
DB_HOST=mysql
DB_PORT=3306
DB_USER=root
DB_PASSWORD=Os51t=Ag/3=B
DB_NAME=emergentETL
```

**MongoDB:**
```env
MONGO_ATLAS_URI=mongodb+srv://BDETLEmergentes:12345@bdemergetesetl.lwsmez4.mongodb.net/
MONGO_DB_NAME=BDETLEmergentes
```

**Kafka:**
```env
KAFKA_BROKER=kafka:9092
KAFKA_TOPIC=datos_sensores
```

## ğŸ› ï¸ Comandos Ãštiles

### Ver logs de un servicio:
```bash
docker logs -f <nombre_servicio>
```

### Reiniciar un servicio:
```bash
docker-compose restart <nombre_servicio>
```

### Detener todos los servicios:
```bash
docker-compose down
```

### Limpiar volÃºmenes y empezar desde cero:
```bash
docker-compose down -v
docker-compose up -d
```

### Verificar estado de los servicios:
```bash
docker-compose ps
```

### Acceder a un contenedor:
```bash
docker exec -it <nombre_servicio> bash
```

### Ver datos en MySQL:
```bash
docker exec -it mysql mysql -uroot -p'Os51t=Ag/3=B' -e "SELECT COUNT(*) FROM emergentETL.predicciones;"
```

## ğŸ› Troubleshooting

### Dashboard no carga
```bash
docker-compose restart dashboard
docker logs -f dashboard
```

### No hay datos en MySQL
```bash
# Verificar productores estÃ¡n corriendo
# Verificar consumers estÃ¡n activos
docker logs -f spark-consumer-em310
```

### Job de ML falla
```bash
# Verificar que hay suficientes datos
docker exec mysql mysql -uroot -p'Os51t=Ag/3=B' -e "SELECT COUNT(*) FROM emergentETL.em310_soterrados;"

# Ver logs del job
docker logs spark-ml-job
```

### Puertos ocupados
```bash
# Cambiar puertos en docker-compose.yml
# Ejemplo: "8502:8501" en lugar de "8501:8501"
```

## ï¿½ Flujo de Datos

1. **Productores** generan datos simulados de sensores IoT cada 5 segundos
2. **Kafka** recibe y bufferea los mensajes en el topic `datos_sensores`
3. **Spark Consumers** procesan el stream en tiempo real
4. **Datos** se guardan simultÃ¡neamente en:
   - MySQL (estructurado)
   - MongoDB Atlas (no estructurado)
5. **Job ML** (manual) entrena modelos y genera predicciones
6. **Dashboard** visualiza datos histÃ³ricos y predicciones

## ğŸ“ TecnologÃ­as Utilizadas

- **Apache Spark 3.5.3** - Big Data processing
- **Apache Kafka 7.5.0** - Message streaming
- **MySQL 8.0** - Base de datos relacional
- **MongoDB 6.0** - Base de datos NoSQL
- **Streamlit** - Dashboard interactivo
- **Plotly** - Visualizaciones interactivas
- **PySpark ML** - Machine Learning distribuido
- **Docker & Docker Compose** - ContenerizaciÃ³n

## ğŸ‘¥ Autores

Desarrollado para el curso de Bases de Datos Emergentes

## ğŸ“ Licencia

Este proyecto es de uso acadÃ©mico.

## ğŸš€ PrÃ³ximas Mejoras

- [ ] Automatizar job de ML con cron
- [ ] Implementar validaciÃ³n cruzada avanzada
- [ ] Agregar mÃ¡s modelos ML (LSTM, Prophet)
- [ ] Sistema de alertas basado en umbrales
- [ ] API REST para acceso a datos
- [ ] Persistencia de modelos entrenados
- [ ] DockerizaciÃ³n de productores

---

**Dashboard URL**: http://localhost:8501  
**Spark Master UI**: http://localhost:18080  
**Spark Worker UI**: http://localhost:8081
